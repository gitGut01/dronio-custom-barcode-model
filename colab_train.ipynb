{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# dronio-custom-barcode-model â€” Colab training\n",
        "\n",
        "This notebook:\n",
        "- clones the repo\n",
        "- installs dependencies\n",
        "- (optionally) generates a small synthetic dataset\n",
        "- starts TensorBoard and MLflow UI\n",
        "- starts training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "# --- Clone repo ---\n",
        "!rm -rf dronio-custom-barcode-model\n",
        "!git clone https://github.com/gitGut01/dronio-custom-barcode-model.git\n",
        "%cd dronio-custom-barcode-model\n",
        "\n",
        "# --- Install deps ---\n",
        "!pip -q install -r requirements.txt\n",
        "\n",
        "# Colab already includes torch/torchvision, but ensure tensorboard is present\n",
        "!pip -q install tensorboard\n",
        "\n",
        "import os\n",
        "os.environ.setdefault('MLFLOW_TRACKING_URI', 'file:' + os.path.abspath('mlruns'))\n",
        "print('MLFLOW_TRACKING_URI=', os.environ['MLFLOW_TRACKING_URI'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dataset"
      },
      "outputs": [],
      "source": [
        "# --- Option A: Load dataset zip from Google Drive ---\n",
        "# 1) Upload your dataset zip to Google Drive\n",
        "# 2) Set DRIVE_ZIP_PATH to that file\n",
        "# 3) This will unzip it into DATA_DIR so you end up with:\n",
        "#    my_dataset/train/labels.csv, my_dataset/train/images/...\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Mount Google Drive under /content/drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    os.makedirs('/content/drive', exist_ok=True)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to your zip in Drive (edit this)\n",
        "DRIVE_ZIP_PATH = '/content/drive/MyDrive/path/to/my_dataset.zip'\n",
        "\n",
        "# Where the dataset should be available in the repo after extraction\n",
        "DATA_DIR = 'my_dataset'\n",
        "\n",
        "# Copy zip into local runtime (faster unzip) and extract\n",
        "LOCAL_ZIP = 'dataset.zip'\n",
        "\n",
        "if DRIVE_ZIP_PATH.endswith('/'):\n",
        "    raise ValueError('DRIVE_ZIP_PATH must be a file path to a .zip, not a folder')\n",
        "\n",
        "print('Copying from Drive:', DRIVE_ZIP_PATH)\n",
        "shutil.copyfile(DRIVE_ZIP_PATH, LOCAL_ZIP)\n",
        "\n",
        "# Clean target dir to avoid mixing datasets\n",
        "!rm -rf \"{DATA_DIR}\"\n",
        "!mkdir -p \"{DATA_DIR}\"\n",
        "\n",
        "# Unzip\n",
        "!unzip -q \"{LOCAL_ZIP}\" -d \"{DATA_DIR}\"\n",
        "\n",
        "# Many zips contain a top-level folder; if so, flatten it.\n",
        "entries = [e for e in os.listdir(DATA_DIR) if not e.startswith('.')]\n",
        "if len(entries) == 1 and os.path.isdir(os.path.join(DATA_DIR, entries[0])):\n",
        "    inner = os.path.join(DATA_DIR, entries[0])\n",
        "    print('Detected nested folder, flattening:', inner)\n",
        "    for name in os.listdir(inner):\n",
        "        shutil.move(os.path.join(inner, name), os.path.join(DATA_DIR, name))\n",
        "    shutil.rmtree(inner)\n",
        "\n",
        "print('Dataset ready at:', os.path.abspath(DATA_DIR))\n",
        "print('Contents:', os.listdir(DATA_DIR))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25363a83",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Option B: Generate a synthetic dataset (instead of using Drive) ---\n",
        "# If you used the Drive zip cell above, you can skip this.\n",
        "# If you run this, it will overwrite DATA_DIR.\n",
        "\n",
        "# Keep this small by default so the notebook runs quickly; increase as needed.\n",
        "# !python scripts/generate_barcode_dataset.py --out {DATA_DIR} --train 2000 --val 200 --test 200 --size-min 96 --size-max 320\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tensorboard"
      },
      "outputs": [],
      "source": [
        "# --- TensorBoard ---\n",
        "# Training will write events to TB_LOGDIR.\n",
        "TB_LOGDIR = 'runs/barcode-ctc'\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {TB_LOGDIR}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlflow_ui"
      },
      "outputs": [],
      "source": [
        "# --- MLflow UI ---\n",
        "# Start an MLflow server inside Colab and open it in a new tab/window.\n",
        "# MLflow data is stored locally under ./mlruns\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "MLRUNS_DIR = os.path.abspath('mlruns')\n",
        "MLFLOW_PORT = 5000\n",
        "\n",
        "# Start mlflow UI in the background\n",
        "_ = subprocess.Popen(\n",
        "    [\n",
        "        'mlflow', 'ui',\n",
        "        '--backend-store-uri', 'file:' + MLRUNS_DIR,\n",
        "        '--host', '0.0.0.0',\n",
        "        '--port', str(MLFLOW_PORT),\n",
        "    ],\n",
        "    stdout=subprocess.DEVNULL,\n",
        "    stderr=subprocess.DEVNULL,\n",
        ")\n",
        "\n",
        "time.sleep(2)\n",
        "\n",
        "from google.colab import output\n",
        "output.serve_kernel_port_as_window(MLFLOW_PORT, path='/')\n",
        "print('MLflow UI should open in a new browser tab/window.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train"
      },
      "outputs": [],
      "source": [
        "# --- Train ---\n",
        "# Enable MLflow + TensorBoard.\n",
        "!python scripts/train_recognizer_ctc.py \\\n",
        "  --data {DATA_DIR} \\\n",
        "  --device cuda \\\n",
        "  --epochs 10 \\\n",
        "  --batch 32 \\\n",
        "  --lr 3e-4 \\\n",
        "  --tb --tb-logdir {TB_LOGDIR} \\\n",
        "  --mlflow --mlflow-tracking-uri file:./mlruns --mlflow-experiment barcode-ctc\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "dronio-custom-barcode-model-colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
