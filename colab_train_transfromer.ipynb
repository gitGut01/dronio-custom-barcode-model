{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# dronio-custom-barcode-model â€” Colab training\n",
        "\n",
        "This notebook:\n",
        "- clones the repo\n",
        "- installs dependencies\n",
        "- (optionally) generates a small synthetic dataset\n",
        "- starts TensorBoard and MLflow UI\n",
        "- starts training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup"
      },
      "outputs": [],
      "source": [
        "# --- Clone repo ---\n",
        "!rm -rf dronio-custom-barcode-model\n",
        "!git clone https://github.com/gitGut01/dronio-custom-barcode-model.git\n",
        "%cd dronio-custom-barcode-model\n",
        "\n",
        "# --- Install deps ---\n",
        "!pip -q install -r requirements.txt\n",
        "\n",
        "# Colab already includes torch/torchvision, but ensure tensorboard is present\n",
        "!pip -q install tensorboard\n",
        "\n",
        "!pip -q install flashlight-text\n",
        "!pip -q install kenlm\n",
        "\n",
        "import os\n",
        "os.environ.setdefault('MLFLOW_TRACKING_URI', 'file:' + os.path.abspath('mlruns'))\n",
        "print('MLFLOW_TRACKING_URI=', os.environ['MLFLOW_TRACKING_URI'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dataset"
      },
      "outputs": [],
      "source": [
        "# --- Option A: Load dataset zip from Google Drive ---\n",
        "# 1) Upload your dataset zip to Google Drive\n",
        "# 2) Set DRIVE_ZIP_PATH to that file\n",
        "# 3) This will unzip it into DATA_DIR so you end up with:\n",
        "#    my_dataset/train/labels.csv, my_dataset/train/images/...\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Mount Google Drive under /content/drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    os.makedirs('/content/drive', exist_ok=True)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to your zip in Drive (edit this)\n",
        "DRIVE_ZIP_PATH = '/content/drive/MyDrive/WarehouseDrone/Datasets/Custom_Barcode_value_dataset/1M.zip'\n",
        "\n",
        "# Where the dataset should be available in the repo after extraction\n",
        "DATA_DIR = 'my_dataset'\n",
        "\n",
        "# Copy zip into local runtime (faster unzip) and extract\n",
        "LOCAL_ZIP = 'dataset.zip'\n",
        "\n",
        "if DRIVE_ZIP_PATH.endswith('/'):\n",
        "    raise ValueError('DRIVE_ZIP_PATH must be a file path to a .zip, not a folder')\n",
        "\n",
        "print('Copying from Drive:', DRIVE_ZIP_PATH)\n",
        "shutil.copyfile(DRIVE_ZIP_PATH, LOCAL_ZIP)\n",
        "\n",
        "# Clean target dir to avoid mixing datasets\n",
        "!rm -rf \"{DATA_DIR}\"\n",
        "!mkdir -p \"{DATA_DIR}\"\n",
        "\n",
        "# Unzip\n",
        "!unzip -q \"{LOCAL_ZIP}\" -d \"{DATA_DIR}\"\n",
        "\n",
        "# Many zips contain a top-level folder; if so, flatten it.\n",
        "entries = [e for e in os.listdir(DATA_DIR) if not e.startswith('.')]\n",
        "if len(entries) == 1 and os.path.isdir(os.path.join(DATA_DIR, entries[0])):\n",
        "    inner = os.path.join(DATA_DIR, entries[0])\n",
        "    print('Detected nested folder, flattening:', inner)\n",
        "    for name in os.listdir(inner):\n",
        "        shutil.move(os.path.join(inner, name), os.path.join(DATA_DIR, name))\n",
        "    shutil.rmtree(inner)\n",
        "\n",
        "print('Dataset ready at:', os.path.abspath(DATA_DIR))\n",
        "print('Contents:', os.listdir(DATA_DIR))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tensorboard"
      },
      "outputs": [],
      "source": [
        "# --- TensorBoard ---\n",
        "# Training will write events to TB_LOGDIR.\n",
        "TB_LOGDIR = 'runs/barcode-transformer-ctc'\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {TB_LOGDIR}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "916a01a7",
      "metadata": {
        "id": "train"
      },
      "outputs": [],
      "source": [
        "# --- Train ---\n",
        "# Enable MLflow + TensorBoard.\n",
        "!python transformer_model/train_transformer_ctc.py \\\n",
        "  --data {DATA_DIR} \\\n",
        "  --device cuda \\\n",
        "  --epochs 10 \\\n",
        "  --batch 128 \\\n",
        "  --lr 3e-4 \\\n",
        "  --amp \\\n",
        "  --tb --tb-logdir {TB_LOGDIR} \\\n",
        "  --mlflow --mlflow-tracking-uri file:./mlruns --mlflow-experiment barcode-transformer-ctc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c11fa82",
      "metadata": {},
      "outputs": [],
      "source": [
        "!zip -r mlruns.zip mlruns"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "colab_train_transfromer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
